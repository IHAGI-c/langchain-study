{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL(LangChain Expression Language)\n",
    "## 기본 예시: 프롬프트 + 모델 + 출력 파서\n",
    "가장 기본적이고 일반적인 사용 사례는 prompt 템플릿과 모델을 사용하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "LANGCHAIN-STUDY\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def langsmith(project_name=None, set_enable=True):\n",
    "\n",
    "    if set_enable:\n",
    "        result = os.environ.get(\"LANGCHAIN_API_KEY\")\n",
    "        if result is None or result.strip() == \"\":\n",
    "            print(\n",
    "                \"LangChain API Key가 설정되지 않았습니다. 참고: https://wikidocs.net/250954\"\n",
    "            )\n",
    "            return\n",
    "        os.environ[\"LANGCHAIN_ENDPOINT\"] = (\n",
    "            \"https://api.smith.langchain.com\"  # LangSmith API 엔드포인트\n",
    "        )\n",
    "        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"  # true: 활성화\n",
    "        os.environ[\"LANGCHAIN_PROJECT\"] = project_name  # 프로젝트명\n",
    "        print(f\"LangSmith 추적을 시작합니다.\\n[프로젝트명]\\n{project_name}\")\n",
    "    else:\n",
    "        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"  # false: 비활성화\n",
    "        print(\"LangSmith 추적을 하지 않습니다.\")\n",
    "\n",
    "\n",
    "langsmith(\"LANGCHAIN-STUDY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿의 활용\n",
    "\n",
    "`PromptTemplate`\n",
    "\n",
    "- 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿\n",
    "- 사용법\n",
    "  - `template`: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 `{}`는 변수를 나타냅니다.\n",
    "  - `input_variables`: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\n",
    "\n",
    "`input_variables`\n",
    "\n",
    "- input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"미국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain 생성\n",
    "\n",
    "### LCEL(LangChain Expression Language)\n",
    "LCEL을 사용하여 다양한 구성 요소를 단일 체인으로 결합\n",
    "\n",
    "```\n",
    "chain = prompt | model | output_parser\n",
    "```\n",
    "\n",
    "`|` 기호는 서로 다른 구성 요소를 연결하고 한 구성 요소의 출력을 다음 구성 요소의 입력으로 전달합니다.\n",
    "\n",
    "`prompt -> model -> output_parser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = AzureChatOpenAI()\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invoke() 호출\n",
    "\n",
    "- python 딕셔너리 형태로 입력값을 전달합니다.(키: 값)\n",
    "- invoke() 함수 호출 시, 입력값을 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=485f250a-243c-46a5-913c-a75492aacffd,id=485f250a-243c-46a5-913c-a75492aacffd; trace=485f250a-243c-46a5-913c-a75492aacffd,id=aed9df12-7d6b-4bba-b9d8-027a110cdbad; trace=485f250a-243c-46a5-913c-a75492aacffd,id=1b14d69c-988a-4112-a9fb-21a8feb7a0ff\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델의 학습 원리를 쉽게 설명하자면, \"경험을 통해 배운다\"라고 할 수 있습니다. 여기서 경험은 데이터, 즉 입력된 정보를 의미합니다. 다음은 인공지능 모델이 어떻게 학습하는지에 대한 간단한 단계입니다.\\n\\n1. **데이터 수집**: 먼저, 모델이 학습할 수 있는 데이터가 필요합니다. 이 데이터는 이미지, 텍스트, 소리 등 다양한 형태일 수 있습니다.\\n\\n2. **데이터 전처리**: 수집된 데이터는 보통 혼란스러울 수 있기 때문에, 모델이 이해할 수 있도록 정리하고 가공합니다. 예를 들어, 이미지를 크기 조정하거나 텍스트를 정제하는 과정이 여기에 포함됩니다.\\n\\n3. **모델 구조 생성**: 인공지능 모델은 여러 층(layer)으로 구성된 신경망(neural network)이라는 구조로 이루어져 있습니다. 각 층은 입력된 정보를 처리하고 다음 층으로 전달하는 역할을 합니다.\\n\\n4. **학습 과정**: 모델은 주어진 데이터에 대해 예측을 시도하고, 그 예측이 실제 결과와 얼마나 차이가 나는지를 평가합니다. 이 과정에서 \\'손실 함수(loss function)\\'라는 것을 사용하여 예측의 정확도를 측정합니다.\\n\\n5. **오류 수정**: 모델이 예측한 결과가 틀렸다면, 그 오류를 기반으로 모델의 내부 파라미터(가중치)를 조정합니다. 이 과정을 \\'역전파(backpropagation)\\'라고 부릅니다.\\n\\n6. **반복 학습**: 위의 과정(예측, 오류 평가, 파라미터 조정)을 여러 번 반복하면서 모델은 점점 더 정확한 예측을 할 수 있게 됩니다. 많은 데이터를 통해 학습할수록 성능이 향상됩니다.\\n\\n7. **검증 및 테스트**: 학습이 끝난 후에는 모델의 성능을 검증하기 위해 새로운 데이터로 테스트합니다. 이 데이터를 통해 모델이 실제 상황에서도 잘 작동하는지를 확인합니다.\\n\\n이러한 과정을 통해 인공지능 모델은 특정 작업을 수행할 수 있는 능력을 가지게 됩니다. 결과적으로, 데이터와 경험을 통해 스스로 학습하고 개선해 나가는 것이 인공지능의 기본 원리입니다.', response_metadata={'token_usage': {'completion_tokens': 497, 'prompt_tokens': 22, 'total_tokens': 519, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_d54531d9eb', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'profanity': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'profanity': {'filtered': False, 'detected': False}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-1b14d69c-988a-4112-a9fb-21a8feb7a0ff-0', usage_metadata={'input_tokens': 22, 'output_tokens': 497, 'total_tokens': 519})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=485f250a-243c-46a5-913c-a75492aacffd,id=485f250a-243c-46a5-913c-a75492aacffd; trace=485f250a-243c-46a5-913c-a75492aacffd,id=1b14d69c-988a-4112-a9fb-21a8feb7a0ff\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=e32c523d-354f-4202-918c-ed26b280a666,id=e32c523d-354f-4202-918c-ed26b280a666; trace=e32c523d-354f-4202-918c-ed26b280a666,id=01f731b6-5f34-4afb-b5cd-465a77f0e9df; trace=e32c523d-354f-4202-918c-ed26b280a666,id=7070d6ab-ea20-4f88-bca0-2b9ff1422cb8\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=e32c523d-354f-4202-918c-ed26b280a666,id=e32c523d-354f-4202-918c-ed26b280a666; trace=e32c523d-354f-4202-918c-ed26b280a666,id=7070d6ab-ea20-4f88-bca0-2b9ff1422cb8\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=a23b0868-0453-45b2-946b-4ced102bbb66,id=a23b0868-0453-45b2-946b-4ced102bbb66; trace=a23b0868-0453-45b2-946b-4ced102bbb66,id=482d7415-848d-4d97-97a6-7996360508c3; trace=a23b0868-0453-45b2-946b-4ced102bbb66,id=e45650d7-7880-4f9e-9698-66e3d654c19c\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=a23b0868-0453-45b2-946b-4ced102bbb66,id=81eb254c-85b8-4191-9b92-db9d30bcbef6; trace=6c4e9fd2-6548-44be-9717-7b5b470b3dcb,id=6c4e9fd2-6548-44be-9717-7b5b470b3dcb; trace=6c4e9fd2-6548-44be-9717-7b5b470b3dcb,id=9effe589-d18d-4fef-a4e6-22dc388a74d9; trace=6c4e9fd2-6548-44be-9717-7b5b470b3dcb,id=e1572d3e-5524-4856-9c73-6206e3e20bd2; trace=a23b0868-0453-45b2-946b-4ced102bbb66,id=a23b0868-0453-45b2-946b-4ced102bbb66; trace=a23b0868-0453-45b2-946b-4ced102bbb66,id=e45650d7-7880-4f9e-9698-66e3d654c19c\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=6c4e9fd2-6548-44be-9717-7b5b470b3dcb,id=4c65cd23-8291-4d59-aa80-74640904d2de\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=6c4e9fd2-6548-44be-9717-7b5b470b3dcb,id=e1572d3e-5524-4856-9c73-6206e3e20bd2; trace=6c4e9fd2-6548-44be-9717-7b5b470b3dcb,id=4c65cd23-8291-4d59-aa80-74640904d2de; trace=6c4e9fd2-6548-44be-9717-7b5b470b3dcb,id=6c4e9fd2-6548-44be-9717-7b5b470b3dcb\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=9d1978d4-e094-4ddd-9920-fb6ad304b127,id=9d1978d4-e094-4ddd-9920-fb6ad304b127; trace=9d1978d4-e094-4ddd-9920-fb6ad304b127,id=c185a1dd-156b-4953-8869-70f872ede8ac; trace=9d1978d4-e094-4ddd-9920-fb6ad304b127,id=310d6d06-e0b3-4b05-bd62-34f0d8840c5e\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=9d1978d4-e094-4ddd-9920-fb6ad304b127,id=523ea57d-1315-4ae6-b55b-4c38a2f3bf1f; trace=9d1978d4-e094-4ddd-9920-fb6ad304b127,id=310d6d06-e0b3-4b05-bd62-34f0d8840c5e; trace=9d1978d4-e094-4ddd-9920-fb6ad304b127,id=9d1978d4-e094-4ddd-9920-fb6ad304b127\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=221f11ed-8826-4fc2-b6e5-cb5182e38352,id=221f11ed-8826-4fc2-b6e5-cb5182e38352; trace=221f11ed-8826-4fc2-b6e5-cb5182e38352,id=896e118e-bdad-4e98-807a-578972edf169; trace=221f11ed-8826-4fc2-b6e5-cb5182e38352,id=fa24a043-a633-482d-b795-60d5289878eb\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=221f11ed-8826-4fc2-b6e5-cb5182e38352,id=e8b14d0f-eb82-478d-a7aa-1fd296f4ae34\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=221f11ed-8826-4fc2-b6e5-cb5182e38352,id=fa24a043-a633-482d-b795-60d5289878eb; trace=221f11ed-8826-4fc2-b6e5-cb5182e38352,id=e8b14d0f-eb82-478d-a7aa-1fd296f4ae34; trace=221f11ed-8826-4fc2-b6e5-cb5182e38352,id=221f11ed-8826-4fc2-b6e5-cb5182e38352\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=99c32e62-8a7b-4524-a0a7-3df8e7995160,id=99c32e62-8a7b-4524-a0a7-3df8e7995160; trace=99c32e62-8a7b-4524-a0a7-3df8e7995160,id=bb460465-11a9-4c85-bb37-58e083b87313; trace=99c32e62-8a7b-4524-a0a7-3df8e7995160,id=0ef89f42-1d47-4e53-af0c-c93142232cba\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=99c32e62-8a7b-4524-a0a7-3df8e7995160,id=b2f51ca5-a982-4307-a314-7e42f80eec5d\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Using legacy API key. Please generate a new API key.\"}')trace=99c32e62-8a7b-4524-a0a7-3df8e7995160,id=0ef89f42-1d47-4e53-af0c-c93142232cba; trace=99c32e62-8a7b-4524-a0a7-3df8e7995160,id=99c32e62-8a7b-4524-a0a7-3df8e7995160; trace=99c32e62-8a7b-4524-a0a7-3df8e7995160,id=b2f51ca5-a982-4307-a314-7e42f80eec5d\n"
     ]
    }
   ],
   "source": [
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 주로 '데이터'와 '학습 알고리즘'을 기반으로 합니다. 간단히 설명하자면 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델은 학습하기 위해 많은 양의 데이터를 필요로 합니다. 이 데이터는 텍스트, 이미지, 소리 등 다양한 형태일 수 있습니다. 예를 들어, 고양이와 개를 구분하는 모델을 만들고 싶다면, 고양이와 개의 사진을 많이 모아야 합니다.\n",
      "\n",
      "2. **훈련(학습)**: 모델은 데이터를 통해 패턴을 배우게 됩니다. 이 단계에서는 모델이 입력(예: 사진)과 출력(예: 고양이 또는 개)을 연결하는 방법을 익히게 됩니다. 이를 위해 수학적 알고리즘이 사용되며, 주로 신경망(neural network)이라는 구조를 활용합니다.\n",
      "\n",
      "3. **손실 함수**: 모델이 예측한 결과와 실제 정답 간의 차이를 계산하는 방법입니다. 이 차이를 줄이기 위해 모델의 파라미터(가중치)를 조정합니다. 손실 함수는 모델이 얼마나 잘 학습하고 있는지를 평가하는 기준이 됩니다.\n",
      "\n",
      "4. **최적화**: 손실 함수를 최소화하기 위해 모델의 파라미터를 조정하는 과정입니다. 이것은 반복적으로 이루어지며, 모델이 점점 더 정확한 예측을 하도록 돕습니다. 보통 '경사 하강법'이라는 방법이 사용됩니다.\n",
      "\n",
      "5. **검증 및 평가**: 학습이 끝난 후, 모델이 새로운 데이터에 대해 얼마나 잘 작동하는지를 평가합니다. 이를 통해 모델의 성능을 확인하고, 필요시 조정할 수 있습니다.\n",
      "\n",
      "6. **실행**: 마지막으로, 학습된 모델은 실제 환경에서 사용됩니다. 예를 들어, 사용자가 고양이 사진을 올리면, 모델이 이를 분석하여 고양이인지 개인지 판단합니다.\n",
      "\n",
      "이러한 과정을 통해 인공지능 모델은 경험을 쌓고, 점점 더 똑똑해져 가는 것입니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"인공지능 모델의 학습 원리를 쉽게 설명하자면, 마치 사람의 학습 과정과 비슷하다고 볼 수 있습니다. 다음은 그 과정의 기본적인 단계입니다.\\n\\n1. **데이터 수집**: 인공지능 모델은 많은 양의 데이터가 필요합니다. 예를 들어, 고양이와 개를 구분하는 모델을 만들고 싶다면, 고양이와 개의 사진을 많이 모아야 합니다.\\n\\n2. **데이터 전처리**: 수집한 데이터는 보통 원래 형태로는 사용할 수 없기 때문에, 정리하고 가공하는 과정이 필요합니다. 사진의 크기를 맞추거나, 필요 없는 정보를 제거하는 등의 작업이 이루어집니다.\\n\\n3. **모델 선택**: 다양한 인공지능 알고리즘 중에서 문제에 적합한 모델을 선택합니다. 예를 들어, 이미지 인식에는 CNN(합성곱 신경망)이라는 모델이 자주 사용됩니다.\\n\\n4. **학습 과정**: 모델은 주어진 데이터를 통해 학습을 시작합니다. 이 과정은 '훈련'이라고도 부르며, 모델이 입력 데이터를 보고 정답(레이블)과 비교하여 얼마나 잘 맞추는지를 평가합니다. 이를 통해 모델의 내부 파라미터(가중치)를 조정하면서 점점 더 정확하게 예측할 수 있도록 합니다.\\n\\n5. **검증**: 학습이 끝난 후, 모델의 성능을 평가하기 위해 새로운 데이터(검증 데이터)를 사용합니다. 이 데이터를 통해 모델이 실제 상황에서도 잘 작동하는지를 확인합니다.\\n\\n6. **예측**: 학습이 완료되고 성능이 검증된 모델은 실제 데이터에 대해 예측을 할 수 있습니다. 예를 들어, 새로운 사진이 들어왔을 때 그것이 고양이인지 개인지 판단할 수 있습니다.\\n\\n7. **지속적인 개선**: 모델은 새로운 데이터가 들어오거나 시간이 지나면서 지속적으로 업데이트되고 개선될 수 있습니다.\\n\\n이러한 과정을 통해 인공지능 모델은 데이터를 이해하고, 패턴을 학습하여 문제를 해결하는 능력을 키워나갑니다.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리를 쉽게 설명하자면, 다음과 같은 과정을 거칩니다:\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 많은 데이터를 모읍니다. 예를 들어, 고양이와 개의 사진을 모아서 모델이 이 두 동물을 구분할 수 있도록 준비합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 모델이 이해할 수 있는 형태로 변환합니다. 예를 들어, 이미지의 크기를 조정하거나, 색상을 표준화하는 등의 작업을 합니다.\n",
      "\n",
      "3. **모델 선택**: 문제에 맞는 적절한 인공지능 모델을 선택합니다. 예를 들어, 이미지 분류를 위해 신경망(Neural Network) 모델을 사용할 수 있습니다.\n",
      "\n",
      "4. **학습**: 모델이 데이터를 통해 패턴을 인식하도록 훈련합니다. 이 과정에서는 데이터의 입력과 정답(예: 고양이 또는 개)을 사용하여 모델의 내부 파라미터를 조정합니다. 이때, 오차를 줄이기 위해 경량화된 알고리즘인 '역전파(Backpropagation)'를 사용합니다.\n",
      "\n",
      "5. **검증**: 학습이 끝난 모델을 새로운 데이터로 테스트하여 얼마나 잘 학습했는지를 평가합니다. 이 단계에서 모델의 성능을 확인할 수 있습니다.\n",
      "\n",
      "6. **조정**: 모델의 성능이 만족스럽지 않으면, 데이터 양을 늘리거나, 모델의 구조를 변경하거나, 하이퍼파라미터(학습률 등)를 조정하여 다시 학습합니다.\n",
      "\n",
      "7. **배포**: 모델이 충분히 학습되면, 실제 응용 프로그램에 배포하여 사용합니다. 예를 들어, 사진을 업로드하면 고양이인지 개인지 분류해 주는 앱으로 활용할 수 있습니다.\n",
      "\n",
      "이런 과정을 통해 인공지능 모델은 데이터를 학습하고, 새로운 데이터를 처리할 수 있는 능력을 갖추게 됩니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 템플릿을 변경하여 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 주어진 상황에 맞는 영어 회화를 작성해 주세요.\n",
    "양식은 [FORMAT]을 참고하여 작성해 주세요.\n",
    "\n",
    "#상황:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화합니다.\n",
    "model = AzureChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# 문자열 출력 파서를 초기화합니다.\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:  \n",
      "  **Waiter:** Good evening! Welcome to our restaurant. How many people are in your party?  \n",
      "  **You:** Just one, please.  \n",
      "  **Waiter:** Great! Here’s the menu. Can I get you something to drink while you look?  \n",
      "  **You:** Yes, I’d like a glass of water, please.  \n",
      "  **Waiter:** Sure! Take your time. Let me know when you’re ready to order.  \n",
      "  **You:** Thank you! I’ll have the grilled chicken salad, please.  \n",
      "  **Waiter:** Excellent choice! Would you like any dressing with that?  \n",
      "  **You:** Yes, please. I’ll have the vinaigrette.  \n",
      "  **Waiter:** Perfect! I’ll get that order in for you.  \n",
      "\n",
      "- 한글 해석:  \n",
      "  **웨이터:** 안녕하세요! 저희 식당에 오신 것을 환영합니다. 몇 분이신가요?  \n",
      "  **당신:** 혼자입니다, 부탁드립니다.  \n",
      "  **웨이터:** 좋습니다! 메뉴를 드리겠습니다. 보시는 동안 음료수는 필요하신가요?  \n",
      "  **당신:** 네, 물 한 잔 주세요.  \n",
      "  **웨이터:** 알겠습니다! 천천히 보세요. 주문 준비되시면 말씀해 주세요.  \n",
      "  **당신:** 감사합니다! 저는 그릴에 구운 치킨 샐러드로 할게요.  \n",
      "  **웨이터:** 훌륭한 선택입니다! 드레싱은 어떤 걸 원하시나요?  \n",
      "  **당신:** 네, 비네그레트로 주세요.  \n",
      "  **웨이터:** 완벽합니다! 주문해 드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:  \n",
      "  **Waiter:** Good evening! Welcome to our restaurant. How can I help you today?  \n",
      "  **You:** Hi! I'd like to see the menu, please.  \n",
      "  **Waiter:** Of course! Here you go. Do you have any questions about the menu?  \n",
      "  **You:** Yes, what do you recommend?  \n",
      "  **Waiter:** Our grilled salmon is very popular, and the pasta primavera is also a favorite.  \n",
      "  **You:** That sounds great! I’ll have the grilled salmon, please.  \n",
      "  **Waiter:** Would you like any sides with that?  \n",
      "  **You:** Yes, I’d like a side salad, please.  \n",
      "  **Waiter:** Perfect! Anything to drink?  \n",
      "  **You:** I’ll have a glass of water, please.  \n",
      "  **Waiter:** Great choice! I’ll put that order in for you.  \n",
      "\n",
      "- 한글 해석:  \n",
      "  **웨이터:** 좋은 저녁입니다! 저희 식당에 오신 것을 환영합니다. 오늘 무엇을 도와드릴까요?  \n",
      "  **당신:** 안녕하세요! 메뉴를 보고 싶어요.  \n",
      "  **웨이터:** 물론이죠! 여기 있습니다. 메뉴에 대해 질문이 있으신가요?  \n",
      "  **당신:** 네, 추천해 주실 만한 것이 있나요?  \n",
      "  **웨이터:** 저희 그릴에 구운 연어가 아주 인기가 많고, 파스타 프리마베라도 인기 있습니다.  \n",
      "  **당신:** 좋네요! 그릴에 구운 연어로 주문할게요.  \n",
      "  **웨이터:** 사이드 메뉴는 무엇을 원하시나요?  \n",
      "  **당신:** 네, 사이드 샐러드를 하나 주세요.  \n",
      "  **웨이터:** 완벽합니다! 음료는 무엇을 드릴까요?  \n",
      "  **당신:** 물 한 잔 주세요.  \n",
      "  **웨이터:** 좋은 선택입니다! 주문을 넣겠습니다."
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "A: Hi there! I’d like to order a pizza, please.\n",
      "B: Sure! What size would you like?\n",
      "A: I’ll have a large, please. Can I get half pepperoni and half veggie?\n",
      "B: Absolutely! Would you like any extra toppings?\n",
      "A: Yes, add some olives on the veggie side.\n",
      "B: Great choice! Would you like any drinks with that?\n",
      "A: Yes, I’ll have a 2-liter soda, please.\n",
      "B: Perfect! Your total comes to $25. Would you like that for delivery or pick-up?\n",
      "A: I’ll pick it up, thank you. How long will it take?\n",
      "B: It should be ready in about 20 minutes.\n",
      "A: Sounds good! Thank you!\n",
      "\n",
      "- 한글 해석:\n",
      "A: 안녕하세요! 피자를 주문하고 싶어요.\n",
      "B: 물론이죠! 어떤 사이즈로 하시겠어요?\n",
      "A: 큰 사이즈로 주세요. 반은 페퍼로니, 반은 채소로 해주세요.\n",
      "B: 알겠습니다! 추가 토핑이 필요하신가요?\n",
      "A: 네, 채소 쪽에 올리브를 추가해 주세요.\n",
      "B: 좋은 선택이에요! 음료는 필요하신가요?\n",
      "A: 네, 2리터 탄산음료 하나 주세요.\n",
      "B: 완벽해요! 총 금액은 25달러입니다. 배달할까요, 아니면 픽업할까요?\n",
      "A: 픽업할게요, 감사합니다. 얼마나 걸릴까요?\n",
      "B: 대략 20분 후에 준비될 거예요.\n",
      "A: 좋네요! 감사합니다!"
     ]
    }
   ],
   "source": [
    "# 이번에는 question 을 '미국에서 피자 주문'으로 설정하여 실행합니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-study-RiqbSEqC-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
